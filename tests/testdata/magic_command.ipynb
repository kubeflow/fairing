{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Trains and Evaluates the MNIST network using a feed dictionary.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.examples.tutorials.mnist import mnist\n",
    "\n",
    "import fairing\n",
    "from fairing import builders\n",
    "from fairing.training import kubeflow\n",
    "\n",
    "DOCKER_REPOSITORY_NAME = 'gcr.io/mrick-gcp'\n",
    "NOTEBOOK_FILE = '/home/jovyan/work/demo.ipynb'\n",
    "fairing.config.set_builder(builders.AppendBuilder(\n",
    "    repository=DOCKER_REPOSITORY_NAME, \n",
    "    notebook_file=NOTEBOOK_FILE))\n",
    "\n",
    "INPUT_DATA_DIR = '/tmp/tensorflow/mnist/input_data/'\n",
    "MAX_STEPS = 2000\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.3\n",
    "HIDDEN_1 = 128\n",
    "HIDDEN_2 = 32\n",
    "\n",
    "# HACK: Ideally we would want to have a unique subpath for each instance of the job, but since we can't\n",
    "# we are instead appending HOSTNAME to the logdir\n",
    "LOG_DIR = os.path.join(os.getenv('TEST_TMPDIR', '/tmp'),\n",
    "                       'tensorflow/mnist/logs/fully_connected_feed/', os.getenv('HOSTNAME', ''))\n",
    "MODEL_DIR = os.path.join(LOG_DIR, 'model.ckpt')\n",
    "\n",
    "@kubeflow.DistributedTraining(worker_count=3, ps_count=1, namespace='kubeflow')\n",
    "class MyModel(object):\n",
    "    def train(self):\n",
    "        self.data_sets = input_data.read_data_sets(INPUT_DATA_DIR)\n",
    "        self.images_placeholder = tf.placeholder(\n",
    "            tf.float32, shape=(BATCH_SIZE, mnist.IMAGE_PIXELS))\n",
    "        self.labels_placeholder = tf.placeholder(tf.int32, shape=(BATCH_SIZE))\n",
    "\n",
    "        logits = mnist.inference(self.images_placeholder,\n",
    "                                 HIDDEN_1,\n",
    "                                 HIDDEN_2)\n",
    "\n",
    "        self.loss = mnist.loss(logits, self.labels_placeholder)\n",
    "        self.train_op = mnist.training(self.loss, LEARNING_RATE)\n",
    "        self.summary = tf.summary.merge_all()\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        self.summary_writer = tf.summary.FileWriter(LOG_DIR, self.sess.graph)\n",
    "        self.sess.run(init)\n",
    "\n",
    "        data_set = self.data_sets.train\n",
    "        for step in xrange(MAX_STEPS):\n",
    "            images_feed, labels_feed = data_set.next_batch(BATCH_SIZE, False)\n",
    "            feed_dict = {\n",
    "                self.images_placeholder: images_feed,\n",
    "                self.labels_placeholder: labels_feed,\n",
    "            }\n",
    "\n",
    "            _, loss_value = self.sess.run([self.train_op, self.loss],\n",
    "                                     feed_dict=feed_dict)\n",
    "            if step % 100 == 0:\n",
    "                print(\"At step {}, loss = {}\".format(step, loss_value))\n",
    "                summary_str = self.sess.run(self.summary, feed_dict=feed_dict)\n",
    "                self.summary_writer.add_summary(summary_str, step)\n",
    "                self.summary_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Uploading gcr.io/mrick-gcp/fairing-job:c3016b0543f815e5e0789726e7feb888335d1f5b0644ba431afce73f02143dd1\n",
      "Pushed image gcr.io/mrick-gcp/fairing-job:c3016b0543f815e5e0789726e7feb888335d1f5b0644ba431afce73f02143dd1\n",
      "Training(s) launched.\n",
      "Waiting for job to start...\n",
      "Waiting for job to start...\n",
      "Waiting for job to start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Use the retry module or similar alternatives.'\n",
      "b'WARNING:tensorflow:From /app/demo.py:65: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use alternatives such as official/mnist/dataset.py from tensorflow/models.'\n",
      "b'From /app/demo.py:65: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use alternatives such as official/mnist/dataset.py from tensorflow/models.'\n",
      "b'WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please write your own downloading logic.'\n",
      "b'From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please write your own downloading logic.'\n",
      "b'WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use urllib or similar directly.'\n",
      "b'From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use urllib or similar directly.'\n",
      "b'WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use tf.data to implement this functionality.'\n",
      "b'From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use tf.data to implement this functionality.'\n",
      "b'WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use tf.data to implement this functionality.'\n",
      "b'From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use tf.data to implement this functionality.'\n",
      "b'WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use alternatives such as official/mnist/dataset.py from tensorflow/models.'\n",
      "b'From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.'\n",
      "b'Instructions for updating:'\n",
      "b'Please use alternatives such as official/mnist/dataset.py from tensorflow/models.'\n",
      "b'2018-12-20 20:13:46.342362: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA'\n",
      "b'Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.'\n",
      "b'Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz'\n",
      "b'Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.'\n",
      "b'Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz'\n",
      "b'Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.'\n",
      "b'Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz'\n",
      "b'Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.'\n",
      "b'Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz'\n",
      "b'At step 0, loss = 2.299762725830078'\n",
      "b'At step 100, loss = 0.43860170245170593'\n",
      "b'At step 200, loss = 0.33306312561035156'\n",
      "b'At step 300, loss = 0.194734588265419'\n",
      "b'At step 400, loss = 0.15986257791519165'\n",
      "b'At step 500, loss = 0.19963376224040985'\n",
      "b'At step 600, loss = 0.08520318567752838'\n",
      "b'At step 700, loss = 0.17603126168251038'\n",
      "b'At step 800, loss = 0.11507140100002289'\n",
      "b'At step 900, loss = 0.23888181149959564'\n",
      "b'At step 1000, loss = 0.10274612158536911'\n",
      "b'At step 1100, loss = 0.07834691554307938'\n",
      "b'At step 1200, loss = 0.07513364404439926'\n",
      "b'At step 1300, loss = 0.06989530473947525'\n",
      "b'At step 1400, loss = 0.08526349812746048'\n",
      "b'At step 1500, loss = 0.0980401411652565'\n",
      "b'At step 1600, loss = 0.08789080381393433'\n",
      "b'At step 1700, loss = 0.2013256549835205'\n",
      "b'At step 1800, loss = 0.04252886027097702'\n",
      "b'At step 1900, loss = 0.03759654983878136'\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
