{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and deploy on Kubeflow from Notebooks\n",
    "\n",
    "This notebook introduces you to using Kubeflow Fairing to train and deploy a model to Kubeflow on Google Kubernetes Engine (GKE), and Google Cloud ML Engine. This notebook demonstrate how to:\n",
    " \n",
    "* Train an XGBoost model in a local notebook,\n",
    "* Use Kubeflow Fairing to train an XGBoost model remotely on Kubeflow,\n",
    "* Use Kubeflow Fairing to train an XGBoost model remotely on Cloud ML Engine,\n",
    "* Use Kubeflow Fairing to deploy a trained model to Kubeflow, and\n",
    "* Call the deployed endpoint for predictions.\n",
    "\n",
    "To learn more about how to run this notebook locally, see the guide to [training and deploying on GCP from a local notebook][gcp-local-notebook].\n",
    "\n",
    "[gcp-local-notebook]: https://kubeflow.org/docs/fairing/gcp-local-notebook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your notebook for training an XGBoost model\n",
    "\n",
    "Import the libraries required to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import joblib\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to split the input file into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(file_name, test_size=0.25):\n",
    "    \"\"\"Read input data and split it into train and test.\"\"\"\n",
    "    data = pd.read_csv(file_name)\n",
    "    data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "    y = data.SalePrice\n",
    "    X = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X.values,\n",
    "                                                      y.values,\n",
    "                                                      test_size=test_size,\n",
    "                                                      shuffle=False)\n",
    "\n",
    "    imputer = SimpleImputer()\n",
    "    train_X = imputer.fit_transform(train_X)\n",
    "    test_X = imputer.transform(test_X)\n",
    "\n",
    "    return (train_X, train_y), (test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to train, evaluate, and save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_X,\n",
    "                train_y,\n",
    "                test_X,\n",
    "                test_y,\n",
    "                n_estimators,\n",
    "                learning_rate):\n",
    "    \"\"\"Train the model using XGBRegressor.\"\"\"\n",
    "    model = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "    model.fit(train_X,\n",
    "            train_y,\n",
    "            early_stopping_rounds=40,\n",
    "            eval_set=[(test_X, test_y)])\n",
    "\n",
    "    print(\"Best RMSE on eval: %.2f with %d rounds\" %\n",
    "               (model.best_score,\n",
    "                model.best_iteration+1))\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_X, test_y):\n",
    "    \"\"\"Evaluate the model performance.\"\"\"\n",
    "    predictions = model.predict(test_X)\n",
    "    logging.info(\"mean_absolute_error=%.2f\", mean_absolute_error(predictions, test_y))\n",
    "\n",
    "def save_model(model, model_file):\n",
    "    \"\"\"Save XGBoost model for serving.\"\"\"\n",
    "    joblib.dump(model, model_file)\n",
    "    logging.info(\"Model export success: %s\", model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class for your model, with methods for training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingServe(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_input = \"ames_dataset/train.csv\"\n",
    "        self.n_estimators = 50\n",
    "        self.learning_rate = 0.1\n",
    "        self.model_file = \"trained_ames_model.dat\"\n",
    "        self.model = None\n",
    "\n",
    "    def train(self):\n",
    "        (train_X, train_y), (test_X, test_y) = read_input(self.train_input)\n",
    "        model = train_model(train_X,\n",
    "                          train_y,\n",
    "                          test_X,\n",
    "                          test_y,\n",
    "                          self.n_estimators,\n",
    "                          self.learning_rate)\n",
    "\n",
    "        eval_model(model, test_X, test_y)\n",
    "        save_model(model, self.model_file)\n",
    "\n",
    "    def predict(self, X, feature_names):\n",
    "        \"\"\"Predict using the model for given ndarray.\"\"\"\n",
    "        if not self.model:\n",
    "            self.model = joblib.load(self.model_file)\n",
    "        # Do any preprocessing\n",
    "        prediction = self.model.predict(data=X)\n",
    "        # Do any postprocessing\n",
    "        return [[prediction.item(0), prediction.item(0)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an XGBoost model in a notebook\n",
    "\n",
    "Call `HousingServe().train()` to train your model, and then evaluate and save your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:177514\n",
      "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-rmse:161858\n",
      "[2]\tvalidation_0-rmse:147237\n",
      "[3]\tvalidation_0-rmse:134132\n",
      "[4]\tvalidation_0-rmse:122224\n",
      "[5]\tvalidation_0-rmse:111538\n",
      "[6]\tvalidation_0-rmse:102142\n",
      "[7]\tvalidation_0-rmse:93392.3\n",
      "[8]\tvalidation_0-rmse:85824.6\n",
      "[9]\tvalidation_0-rmse:79667.6\n",
      "[10]\tvalidation_0-rmse:73463.4\n",
      "[11]\tvalidation_0-rmse:68059.4\n",
      "[12]\tvalidation_0-rmse:63350.5\n",
      "[13]\tvalidation_0-rmse:59732.1\n",
      "[14]\tvalidation_0-rmse:56260.7\n",
      "[15]\tvalidation_0-rmse:53392.6\n",
      "[16]\tvalidation_0-rmse:50770.8\n",
      "[17]\tvalidation_0-rmse:48107.8\n",
      "[18]\tvalidation_0-rmse:45923.9\n",
      "[19]\tvalidation_0-rmse:44154.2\n",
      "[20]\tvalidation_0-rmse:42488.1\n",
      "[21]\tvalidation_0-rmse:41263.3\n",
      "[22]\tvalidation_0-rmse:40212.8\n",
      "[23]\tvalidation_0-rmse:39089.1\n",
      "[24]\tvalidation_0-rmse:37691.1\n",
      "[25]\tvalidation_0-rmse:36875.2\n",
      "[26]\tvalidation_0-rmse:36276.2\n",
      "[27]\tvalidation_0-rmse:35444.1\n",
      "[28]\tvalidation_0-rmse:34831.5\n",
      "[29]\tvalidation_0-rmse:34205.4\n",
      "[30]\tvalidation_0-rmse:33831.9\n",
      "[31]\tvalidation_0-rmse:33183.6\n",
      "[32]\tvalidation_0-rmse:33019.4\n",
      "[33]\tvalidation_0-rmse:32680\n",
      "[34]\tvalidation_0-rmse:32438.5\n",
      "[35]\tvalidation_0-rmse:32130.4\n",
      "[36]\tvalidation_0-rmse:31644.2\n",
      "[37]\tvalidation_0-rmse:31248.9\n",
      "[38]\tvalidation_0-rmse:31059.8\n",
      "[39]\tvalidation_0-rmse:30862.4\n",
      "[40]\tvalidation_0-rmse:30754\n",
      "[41]\tvalidation_0-rmse:30561.6\n",
      "[42]\tvalidation_0-rmse:30416.9\n",
      "[43]\tvalidation_0-rmse:30156.4\n",
      "[44]\tvalidation_0-rmse:29852.9\n",
      "[45]\tvalidation_0-rmse:29486.6\n",
      "[46]\tvalidation_0-rmse:29158.8\n",
      "[47]\tvalidation_0-rmse:29017\n",
      "[48]\tvalidation_0-rmse:28973.9\n",
      "[49]\tvalidation_0-rmse:28787.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean_absolute_error=18173.15\n",
      "Model export success: trained_ames_model.dat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE on eval: 28787.72 with 50 rounds\n"
     ]
    }
   ],
   "source": [
    "HousingServe().train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Kubeflow Fairing\n",
    "\n",
    "Import the `fairing` library and configure the GCP environment that your training or prediction job will run in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fairing\n",
    "from fairing import TrainJob\n",
    "from fairing.cloud import docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an XGBoost model remotely with private docker registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't determine namespace automatically. Using 'default' namespace but recomend to provide namespace explicitly. Using 'default' namespace might result in unable to mount some required secrets in cloud backends.\n",
      "Using default base docker image: registry.hub.docker.com/library/python:3.6.2\n",
      "Using builder: <class 'fairing.builders.docker.docker.DockerBuilder'>\n",
      "Building the docker image.\n",
      "Building image using docker\n",
      "Docker command: ['python', '/app/function_shim.py', '--serialized_fn_file', '/app/pickled_fn.p', '--python_version', '3.6.2']\n",
      "/home/coursera/anaconda3/envs/ksenv/lib/python3.6/site-packages/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "Creating docker context: /tmp/fairing_context_jb7ks928\n",
      "/home/coursera/anaconda3/envs/ksenv/lib/python3.6/site-packages/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "Building docker image shikhabitgrit/fairing-job:1FC14C10...\n",
      "Build output: Step 1/7 : FROM registry.hub.docker.com/library/python:3.6.2\n",
      "Build output: \n",
      "Build output: ---> 26acbad26a2c\n",
      "Build output: Step 2/7 : WORKDIR /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 53b4608f0bf4\n",
      "Build output: Step 3/7 : ENV FAIRING_RUNTIME 1\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> d8d0661d7848\n",
      "Build output: Step 4/7 : COPY /app//requirements.txt /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 5af076a8e9a6\n",
      "Build output: Step 5/7 : RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> c375de9c33d9\n",
      "Build output: Step 6/7 : COPY /app/ /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 3395281c100d\n",
      "Build output: Step 7/7 : CMD python /app/function_shim.py --serialized_fn_file /app/pickled_fn.p --python_version 3.6.2\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 3242e7d63a6a\n",
      "Push finished: {'ID': 'sha256:3242e7d63a6a88c69faa56a4f224c50bd54fefcbc45894574add28dc49f99ae8'}\n",
      "Build output: Successfully built 3242e7d63a6a\n",
      "Build output: Successfully tagged shikhabitgrit/fairing-job:1FC14C10\n",
      "Publishing image shikhabitgrit/fairing-job:1FC14C10...\n",
      "Push output: The push refers to repository [docker.io/shikhabitgrit/fairing-job] None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Pushing [===>                                               ]  35.84kB/517.9kB\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Pushing [===============================>                   ]  330.8kB/517.9kB\n",
      "Push output: Pushing [==================================================>]  529.9kB\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Pushing [>                                                  ]  525.3kB/123.4MB\n",
      "Push output: Pushing [>                                                  ]  1.064MB/123.4MB\n",
      "Push output: Pushing [>                                                  ]  1.592MB/123.4MB\n",
      "Push output: Pushed None\n",
      "Push output: Pushing [>                                                  ]  2.126MB/123.4MB\n",
      "Push output: Pushing [=>                                                 ]  2.683MB/123.4MB\n",
      "Push output: Pushing [=>                                                 ]   3.22MB/123.4MB\n",
      "Push output: Pushing [=>                                                 ]  3.748MB/123.4MB\n",
      "Push output: Pushing [=>                                                 ]  4.276MB/123.4MB\n",
      "Push output: Pushing [=>                                                 ]   4.81MB/123.4MB\n",
      "Push output: Pushing [==>                                                ]  5.359MB/123.4MB\n",
      "Push output: Pushing [==>                                                ]  5.905MB/123.4MB\n",
      "Push output: Pushing [==>                                                ]  6.973MB/123.4MB\n",
      "Push output: Pushing [===>                                               ]  7.498MB/123.4MB\n",
      "Push output: Pushing [===>                                               ]  8.023MB/123.4MB\n",
      "Push output: Pushing [===>                                               ]  9.126MB/123.4MB\n",
      "Push output: Pushing [===>                                               ]  9.683MB/123.4MB\n",
      "Push output: Pushing [====>                                              ]  10.77MB/123.4MB\n",
      "Push output: Pushing [====>                                              ]  11.31MB/123.4MB\n",
      "Push output: Pushing [====>                                              ]  11.85MB/123.4MB\n",
      "Push output: Pushing [=====>                                             ]  12.91MB/123.4MB\n",
      "Push output: Pushing [=====>                                             ]  13.47MB/123.4MB\n",
      "Push output: Pushing [=====>                                             ]  14.02MB/123.4MB\n",
      "Push output: Pushing [======>                                            ]  15.08MB/123.4MB\n",
      "Push output: Pushing [======>                                            ]  16.19MB/123.4MB\n",
      "Push output: Pushing [=======>                                           ]   17.3MB/123.4MB\n",
      "Push output: Pushing [=======>                                           ]  19.53MB/123.4MB\n",
      "Push output: Pushing [========>                                          ]  20.09MB/123.4MB\n",
      "Push output: Pushing [========>                                          ]  21.76MB/123.4MB\n",
      "Push output: Pushing [=========>                                         ]  23.98MB/123.4MB\n",
      "Push output: Pushing [=========>                                         ]  24.54MB/123.4MB\n",
      "Push output: Pushing [===========>                                       ]  27.26MB/123.4MB\n",
      "Push output: Pushing [===========>                                       ]   27.8MB/123.4MB\n",
      "Push output: Pushing [===========>                                       ]  29.46MB/123.4MB\n",
      "Push output: Pushing [============>                                      ]  30.52MB/123.4MB\n",
      "Push output: Pushing [============>                                      ]  31.08MB/123.4MB\n",
      "Push output: Pushing [=============>                                     ]  32.15MB/123.4MB\n",
      "Push output: Pushing [=============>                                     ]  32.71MB/123.4MB\n",
      "Push output: Pushing [=============>                                     ]  33.24MB/123.4MB\n",
      "Push output: Pushing [=============>                                     ]  33.78MB/123.4MB\n",
      "Push output: Pushing [==============>                                    ]  34.86MB/123.4MB\n",
      "Push output: Pushing [==============>                                    ]  35.39MB/123.4MB\n",
      "Push output: Pushing [===============>                                   ]  37.03MB/123.4MB\n",
      "Push output: Pushing [===============>                                   ]  37.56MB/123.4MB\n",
      "Push output: Pushing [===============>                                   ]  38.09MB/123.4MB\n",
      "Push output: Pushing [===============>                                   ]  39.15MB/123.4MB\n",
      "Push output: Pushing [================>                                  ]   39.7MB/123.4MB\n",
      "Push output: Pushing [================>                                  ]  40.76MB/123.4MB\n",
      "Push output: Pushing [================>                                  ]  41.86MB/123.4MB\n",
      "Push output: Pushing [=================>                                 ]  42.92MB/123.4MB\n",
      "Push output: Pushing [=================>                                 ]  43.45MB/123.4MB\n",
      "Push output: Pushing [=================>                                 ]  43.98MB/123.4MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Push output: Pushing [==================>                                ]  45.05MB/123.4MB\n",
      "Push output: Pushing [==================>                                ]  45.57MB/123.4MB\n",
      "Push output: Pushing [==================>                                ]  46.66MB/123.4MB\n",
      "Push output: Pushing [===================>                               ]  47.74MB/123.4MB\n",
      "Push output: Pushing [===================>                               ]  48.27MB/123.4MB\n",
      "Push output: Pushing [===================>                               ]  48.82MB/123.4MB\n",
      "Push output: Pushing [====================>                              ]  49.91MB/123.4MB\n",
      "Push output: Pushing [====================>                              ]  50.45MB/123.4MB\n",
      "Push output: Pushing [====================>                              ]  50.98MB/123.4MB\n",
      "Push output: Pushing [=====================>                             ]  52.04MB/123.4MB\n",
      "Push output: Pushing [=====================>                             ]  53.12MB/123.4MB\n",
      "Push output: Pushing [=====================>                             ]  53.67MB/123.4MB\n",
      "Push output: Pushing [======================>                            ]  54.73MB/123.4MB\n",
      "Push output: Pushing [======================>                            ]  55.27MB/123.4MB\n",
      "Push output: Pushing [======================>                            ]  56.39MB/123.4MB\n",
      "Push output: Pushing [=======================>                           ]  56.92MB/123.4MB\n",
      "Push output: Pushing [=======================>                           ]  57.47MB/123.4MB\n",
      "Push output: Pushing [=======================>                           ]     58MB/123.4MB\n",
      "Push output: Pushing [=======================>                           ]  59.09MB/123.4MB\n",
      "Push output: Pushing [========================>                          ]  59.62MB/123.4MB\n",
      "Push output: Pushing [========================>                          ]  61.23MB/123.4MB\n",
      "Push output: Pushing [=========================>                         ]   62.3MB/123.4MB\n",
      "Push output: Pushing [=========================>                         ]  62.83MB/123.4MB\n",
      "Push output: Pushing [=========================>                         ]  63.92MB/123.4MB\n",
      "Push output: Pushing [==========================>                        ]  64.48MB/123.4MB\n",
      "Push output: Pushing [==========================>                        ]  65.03MB/123.4MB\n",
      "Push output: Pushing [==========================>                        ]  66.14MB/123.4MB\n",
      "Push output: Pushing [===========================>                       ]  67.23MB/123.4MB\n",
      "Push output: Pushing [===========================>                       ]  68.34MB/123.4MB\n",
      "Push output: Pushing [============================>                      ]  69.45MB/123.4MB\n",
      "Push output: Pushing [============================>                      ]  70.01MB/123.4MB\n",
      "Push output: Pushing [============================>                      ]  70.54MB/123.4MB\n",
      "Push output: Pushing [============================>                      ]  71.08MB/123.4MB\n",
      "Push output: Pushing [=============================>                     ]  71.61MB/123.4MB\n",
      "Push output: Pushing [=============================>                     ]  72.68MB/123.4MB\n",
      "Push output: Pushing [=============================>                     ]  73.21MB/123.4MB\n",
      "Push output: Pushing [=============================>                     ]  73.74MB/123.4MB\n",
      "Push output: Pushing [==============================>                    ]  74.27MB/123.4MB\n",
      "Push output: Pushing [==============================>                    ]  74.81MB/123.4MB\n",
      "Push output: Pushing [==============================>                    ]   75.9MB/123.4MB\n",
      "Push output: Pushing [==============================>                    ]  76.43MB/123.4MB\n",
      "Push output: Pushing [===============================>                   ]  76.98MB/123.4MB\n",
      "Push output: Pushing [===============================>                   ]  77.51MB/123.4MB\n",
      "Push output: Pushing [===============================>                   ]  78.59MB/123.4MB\n",
      "Push output: Pushing [================================>                  ]  79.13MB/123.4MB\n",
      "Push output: Pushing [================================>                  ]   80.2MB/123.4MB\n",
      "Push output: Pushing [================================>                  ]  80.72MB/123.4MB\n",
      "Push output: Pushing [================================>                  ]  81.25MB/123.4MB\n",
      "Push output: Pushing [=================================>                 ]  82.33MB/123.4MB\n",
      "Push output: Pushing [=================================>                 ]  82.88MB/123.4MB\n",
      "Push output: Pushing [==================================>                ]  83.94MB/123.4MB\n",
      "Push output: Pushing [==================================>                ]  84.49MB/123.4MB\n",
      "Push output: Pushing [==================================>                ]   86.1MB/123.4MB\n",
      "Push output: Pushing [===================================>               ]  87.19MB/123.4MB\n",
      "Push output: Pushing [===================================>               ]  87.73MB/123.4MB\n",
      "Push output: Pushing [===================================>               ]  88.81MB/123.4MB\n",
      "Push output: Pushing [====================================>              ]  90.41MB/123.4MB\n",
      "Push output: Pushing [=====================================>             ]  91.49MB/123.4MB\n",
      "Push output: Pushing [=====================================>             ]  92.05MB/123.4MB\n",
      "Push output: Pushing [=====================================>             ]  93.15MB/123.4MB\n",
      "Push output: Pushing [======================================>            ]  94.25MB/123.4MB\n",
      "Push output: Pushing [======================================>            ]  95.88MB/123.4MB\n",
      "Push output: Pushing [=======================================>           ]  96.98MB/123.4MB\n",
      "Push output: Pushing [=======================================>           ]  98.06MB/123.4MB\n",
      "Push output: Pushing [========================================>          ]   99.7MB/123.4MB\n",
      "Push output: Pushing [========================================>          ]  100.3MB/123.4MB\n",
      "Push output: Pushing [=========================================>         ]  101.9MB/123.4MB\n",
      "Push output: Pushing [=========================================>         ]    103MB/123.4MB\n",
      "Push output: Pushing [==========================================>        ]    104MB/123.4MB\n",
      "Push output: Pushing [==========================================>        ]  105.6MB/123.4MB\n",
      "Push output: Pushing [===========================================>       ]  107.3MB/123.4MB\n",
      "Push output: Pushing [===========================================>       ]  108.4MB/123.4MB\n",
      "Push output: Pushing [============================================>      ]  109.5MB/123.4MB\n",
      "Push output: Pushing [============================================>      ]  110.5MB/123.4MB\n",
      "Push output: Pushing [=============================================>     ]  111.1MB/123.4MB\n",
      "Push output: Pushing [=============================================>     ]  112.1MB/123.4MB\n",
      "Push output: Pushing [=============================================>     ]  112.7MB/123.4MB\n",
      "Push output: Pushing [=============================================>     ]  113.2MB/123.4MB\n",
      "Push output: Pushing [==============================================>    ]  114.3MB/123.4MB\n",
      "Push output: Pushing [==============================================>    ]  115.4MB/123.4MB\n",
      "Push output: Pushing [==============================================>    ]  115.9MB/123.4MB\n",
      "Push output: Pushing [===============================================>   ]  116.9MB/123.4MB\n",
      "Push output: Pushing [===============================================>   ]  117.5MB/123.4MB\n",
      "Push output: Pushing [================================================>  ]  118.5MB/123.4MB\n",
      "Push output: Pushing [================================================>  ]    119MB/123.4MB\n",
      "Push output: Pushing [================================================>  ]  119.6MB/123.4MB\n",
      "Push output: Pushing [================================================>  ]  120.1MB/123.4MB\n",
      "Push output: Pushing [=================================================> ]  121.2MB/123.4MB\n",
      "Push output: Pushing [=================================================> ]  121.7MB/123.4MB\n",
      "Push output: Pushing [=================================================> ]  122.2MB/123.4MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Push output: Pushing [=================================================> ]  123.3MB/123.4MB\n",
      "Push output: Pushing [==================================================>]  124.8MB\n",
      "Push output: Pushing [==================================================>]  125.9MB\n",
      "Push output: Pushing [==================================================>]    127MB\n",
      "Push output: Pushing [==================================================>]    128MB\n",
      "Push output: Pushing [==================================================>]  128.6MB\n",
      "Push output: Pushing [==================================================>]  129.3MB\n",
      "Push output: Pushed None\n",
      "Push output: 1FC14C10: digest: sha256:02e6f3db41041c34cd22ab13d4669848d82f79d0341e7707ef3ace8503da2fde size: 2844 None\n",
      "Push finished: {'Tag': '1FC14C10', 'Digest': 'sha256:02e6f3db41041c34cd22ab13d4669848d82f79d0341e7707ef3ace8503da2fde', 'Size': 2844}\n",
      "/home/coursera/anaconda3/envs/ksenv/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "The job fairing-job-xggxn launched.\n",
      "Waiting for fairing-job-xggxn-rtpr7 to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:13:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:177514\n",
      "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-rmse:161858\n",
      "[2]\tvalidation_0-rmse:147237\n",
      "[3]\tvalidation_0-rmse:134132\n",
      "[4]\tvalidation_0-rmse:122224\n",
      "[5]\tvalidation_0-rmse:111538\n",
      "[6]\tvalidation_0-rmse:102142\n",
      "[7]\tvalidation_0-rmse:93392.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning up job fairing-job-xggxn...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\tvalidation_0-rmse:85824.6\n",
      "[9]\tvalidation_0-rmse:79667.6\n",
      "[10]\tvalidation_0-rmse:73463.4\n",
      "[11]\tvalidation_0-rmse:68059.4\n",
      "[12]\tvalidation_0-rmse:63350.5\n",
      "[13]\tvalidation_0-rmse:59732.1\n",
      "[14]\tvalidation_0-rmse:56260.7\n",
      "[15]\tvalidation_0-rmse:53392.6\n",
      "[16]\tvalidation_0-rmse:50770.8\n",
      "[17]\tvalidation_0-rmse:48107.8\n",
      "[18]\tvalidation_0-rmse:45923.9\n",
      "[19]\tvalidation_0-rmse:44154.2\n",
      "[20]\tvalidation_0-rmse:42488.1\n",
      "[21]\tvalidation_0-rmse:41263.3\n",
      "[22]\tvalidation_0-rmse:40212.8\n",
      "[23]\tvalidation_0-rmse:39089.1\n",
      "[24]\tvalidation_0-rmse:37691.1\n",
      "[25]\tvalidation_0-rmse:36875.2\n",
      "[26]\tvalidation_0-rmse:36276.2\n",
      "[27]\tvalidation_0-rmse:35444.1\n",
      "[28]\tvalidation_0-rmse:34831.5\n",
      "[29]\tvalidation_0-rmse:34205.4\n",
      "[30]\tvalidation_0-rmse:33831.9\n",
      "[31]\tvalidation_0-rmse:33183.6\n",
      "[32]\tvalidation_0-rmse:33019.4\n",
      "[33]\tvalidation_0-rmse:32680\n",
      "[34]\tvalidation_0-rmse:32438.5\n",
      "[35]\tvalidation_0-rmse:32130.4\n",
      "[36]\tvalidation_0-rmse:31644.2\n",
      "[37]\tvalidation_0-rmse:31248.9\n",
      "[38]\tvalidation_0-rmse:31059.8\n",
      "[39]\tvalidation_0-rmse:30862.4\n",
      "[40]\tvalidation_0-rmse:30754\n",
      "[41]\tvalidation_0-rmse:30561.6\n",
      "[42]\tvalidation_0-rmse:30416.9\n",
      "[43]\tvalidation_0-rmse:30156.4\n",
      "[44]\tvalidation_0-rmse:29852.9\n",
      "[45]\tvalidation_0-rmse:29486.6\n",
      "[46]\tvalidation_0-rmse:29158.8\n",
      "[47]\tvalidation_0-rmse:29017\n",
      "[48]\tvalidation_0-rmse:28973.9\n",
      "[49]\tvalidation_0-rmse:28787.7\n",
      "mean_absolute_error=18173.15\n",
      "Model export success: trained_ames_model.dat\n",
      "Best RMSE on eval: 28787.72 with 50 rounds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fairing-job-xggxn'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOCKER_REGISTRY = \"shikhabitgrit\" #add your private registry here\n",
    "\n",
    "from fairing.backends import KubernetesBackend\n",
    "\n",
    "train_job = TrainJob(HousingServe,\n",
    "                     input_files=['ames_dataset/train.csv', \"requirements.txt\"],\n",
    "                     docker_registry=DOCKER_REGISTRY, backend=KubernetesBackend(),\n",
    "                     pod_spec_mutators=[fairing.cloud.docker.add_docker_credentials_if_exists])\n",
    "train_job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Set up for training and predictions on GCP\n",
    "Configure the GCP environment that your training or prediction job will run in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an XGBoost model remotely on Kubeflow\n",
    "\n",
    "Import the `TrainJob` and `KubeflowGKEBackend` classes. Kubeflow Fairing packages the `HousingServe` class, the training data, and the training job's software prerequisites as a Docker image. Then Kubeflow Fairing deploys and runs the training job on Kubeflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HousingServe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e95ffed48da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfairing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKubeflowGKEBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_job = TrainJob(HousingServe, input_files=['ames_dataset/train.csv', \"requirements.txt\"],\n\u001b[0m\u001b[1;32m      4\u001b[0m                      docker_registry=DOCKER_REGISTRY, backend=KubeflowGKEBackend())\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HousingServe' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from fairing.backends import KubeflowGKEBackend\n",
    "train_job = TrainJob(HousingServe, input_files=['ames_dataset/train.csv', \"requirements.txt\"],\n",
    "                     docker_registry=DOCKER_REGISTRY, backend=KubeflowGKEBackend())\n",
    "train_job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an XGBoost model remotely on Cloud ML Engine\n",
    "\n",
    "Import the `TrainJob` and `GCPManagedBackend` classes. Kubeflow Fairing packages the `HousingServe` class, the training data, and the training job's software prerequisites as a Docker image. Then Kubeflow Fairing deploys and runs the training job on Cloud ML Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fairing import TrainJob\n",
    "from fairing.backends import GCPManagedBackend\n",
    "train_job = TrainJob(HousingServe, input_files=['ames_dataset/train.csv', \"requirements.txt\"],\n",
    "                     docker_registry=DOCKER_REGISTRY, backend=GCPManagedBackend())\n",
    "train_job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model to Kubeflow for predictions\n",
    "\n",
    "Import the `PredictionEndpoint` and `KubeflowGKEBackend` classes. Kubeflow Fairing packages the `HousingServe` class, the trained model, and the prediction endpoint's software prerequisites as a Docker image. Then Kubeflow Fairing deploys and runs the prediction endpoint on Kubeflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fairing import PredictionEndpoint\n",
    "from fairing.backends import KubeflowGKEBackend\n",
    "endpoint = PredictionEndpoint(HousingServe, input_files=['trained_ames_model.dat', \"requirements.txt\"],\n",
    "                              docker_registry=DOCKER_REGISTRY, backend=KubeflowGKEBackend())\n",
    "endpoint.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the prediction endpoint\n",
    "\n",
    "Create a test dataset, then call the endpoint on Kubeflow for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = read_input(\"ames_dataset/train.csv\")\n",
    "endpoint.predict_nparray(test_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the prediction endpoint\n",
    "\n",
    "Delete the prediction endpoint created by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
